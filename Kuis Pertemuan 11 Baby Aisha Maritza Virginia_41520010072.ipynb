{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPOkXrNLUsQbEnASY+ptPj/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qRVtVmjT3Smn"},"outputs":[],"source":["### Assuming you have cloned the Cycle GAN repo from github: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n","### run download_cyclegan_model.sh script to download pretrained summer2winter_yosemite_pretrained model (instructions on github page)\n","### Create a jupyter notebook and follow the below code snippets\n","\n","from models import create_model\n","from options.test_options import TestOptions\n","import torch\n","from polygraphy.backend.onnx import fold_constants\n","import onnx\n","\n","opt = TestOptions.parse()\n","opt.netG = 'resnet_9blocks'\n","opt.norm = 'instance'\n","opt.checkpoints_dir = './checkpoints' ### directory storing the pre-trained model\n","opt.name = 'summer2winter_yosemite_pretrained'\n","\n","model = create_model(opt)\n","model.setup(opt)\n","\n","### conversion to onnx\n","dummy_inp = torch.rand(1, 3, 256, 256)\n","onnx_filepath = './summer2winter_yosemite.onnx'\n","torch.onnx.export(model, dummy_inp, onnx_filepath, opset_version=10, input_names = ['inp_img'])\n","\n","### optional step to do Constant folding which involves pre-computing expressions that do not depend on runtime information\n","converted_onnx_model = onnx.load('./summer2winter_yosemite.onnx')\n","constant_folded_model = fold_constants(onnx_model)\n","onnx.save(constant_folded_model, './summer2winter_yosemite_folded.onnx')\n","\n","### This will give you converted onnx model, which can itself be used for on-device deployment"]},{"cell_type":"code","source":["python3 -m venv openvino_env\n","\n","source openvino_env/bin/activate\n","\n","python -m pip install --upgrade pip\n","\n","pip install openvino-dev==2022.1.0. ### tested on this version currently"],"metadata":{"id":"d2XTDsNT32F3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mo -h ### This will return the help message for Model Optimizer if installation finished successfully"],"metadata":{"id":"_irVA5Z7358n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### To convert, run the following in your terminal (you can use either onnx model or the folded onnx model)\n","### input_model - specify your input onnx file\n","### data_type - use fp16 to convert model to fp16 precision for better performance\n","### output_dir - directory where your openvino files will be saved\n","\n","mo --input_model summer2winter_yosemite_folded.onnx --data_type fp16 --output_dir \"./summer2winter_yosemite_openvino\""],"metadata":{"id":"IoAz3IG537a-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Pytorch Model Inference\n","\n","from util.util import tensor2im\n","from data.base_dataset import get_transform\n","from PIL import Image\n","import numpy as np\n","\n","input_image_filename = 'Yosemite_summer.jpg'\n","input_image = Image.open(input_image_filename).convert('RGB')\n","transformation = get_transform(opt, grayscale = False)\n","transformed_img = transformation(input_image).unsqueeze(0)\n","\n","if opt.eval:\n","  model.eval()\n","with torch.no_grad():\n","  output_image = model.netG_A(transformed_img)\n","\n","output_image = tensor2im(output_image) ### final Pytorch result image\n","\n","### OpenVino Model Inference\n","from openvino.inference_engine import IECore, IENetwork\n","from openvino.runtime import Core\n","\n","ie_obj = IECore()\n","\n","openvino_network = ie_obj.read_network(model = 'summer2winter_yosemite_folded.xml', weights = 'summer2winter_yosemite_folded.bin')\n","executable_network = ie_obj.load_network(network = openvino_network, device='CPU')\n","\n","openvino_output = executable_network.infer({'inp_img': transformed_img})\n","\n","arr_key = list(openvino_output.keys())[0] ### get key for putput image\n","openvino_output_img = torch.from_numpy(np.asarray(openvino_output[arr_key]))\n","openvino_output_image = tensor2im(openvino_output_img) ### final OpenVino result image"],"metadata":{"id":"C1zpMne93_G3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (30, 30))\n","plt.subplot(1, 2, 1)\n","plt.gca().set_title('Pytorch Output', fontsize = 'xx-large')\n","plt.imshow(output_image)\n","\n","plt.subplot(1, 2, 2)\n","plt.gca().set_title('OpenVino Output', fontsize = 'xx-large')\n","plt.imshow(openvino_output_image)"],"metadata":{"id":"ZWQG9JEY4Aj3"},"execution_count":null,"outputs":[]}]}